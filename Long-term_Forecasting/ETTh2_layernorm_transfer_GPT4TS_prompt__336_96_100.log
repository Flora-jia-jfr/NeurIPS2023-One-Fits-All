self.enc_in = 7
self.data_x = (8640, 7)
train 57463
self.enc_in = 7
self.data_x = (3216, 7)
val 19495
self.enc_in = 7
self.data_x = (3216, 7)
test 19495
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
Epoch: 1 cost time: 81.88649988174438
Epoch: 1, Steps: 224 | Train Loss: 0.5014292 Vali Loss: 0.2186056
lr = 0.0009938442
Validation loss decreased (inf --> 0.218606).  Saving model ...
Epoch: 2 cost time: 103.38030314445496
Epoch: 2, Steps: 224 | Train Loss: 0.3577084 Vali Loss: 0.2302689
lr = 0.0009755285
EarlyStopping counter: 1 out of 3
Epoch: 3 cost time: 106.05663633346558
Epoch: 3, Steps: 224 | Train Loss: 0.3119035 Vali Loss: 0.2190922
lr = 0.0009455038
EarlyStopping counter: 2 out of 3
Epoch: 4 cost time: 105.49544835090637
Epoch: 4, Steps: 224 | Train Loss: 0.2899285 Vali Loss: 0.2178473
lr = 0.0009045095
Validation loss decreased (0.218606 --> 0.217847).  Saving model ...
Epoch: 5 cost time: 104.57303166389465
Epoch: 5, Steps: 224 | Train Loss: 0.2775271 Vali Loss: 0.2172146
lr = 0.0008535549
Validation loss decreased (0.217847 --> 0.217215).  Saving model ...
Epoch: 6 cost time: 101.0521867275238
Epoch: 6, Steps: 224 | Train Loss: 0.2654608 Vali Loss: 0.2174165
lr = 0.0007938947
EarlyStopping counter: 1 out of 3
Epoch: 7 cost time: 95.4650514125824
Epoch: 7, Steps: 224 | Train Loss: 0.2518143 Vali Loss: 0.2216102
lr = 0.0007269980
EarlyStopping counter: 2 out of 3
Epoch: 8 cost time: 91.30336999893188
Epoch: 8, Steps: 224 | Train Loss: 0.2413079 Vali Loss: 0.2184501
lr = 0.0006545120
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
test shape: (76, 256, 96, 1) (76, 256, 96, 1)
test shape: (19456, 96, 1) (19456, 96, 1)
mae:0.3621, mse:0.3107, rmse:0.5574, smape:54.8947
self.enc_in = 7
self.data_x = (8640, 7)
train 57463
self.enc_in = 7
self.data_x = (3216, 7)
val 19495
self.enc_in = 7
self.data_x = (3216, 7)
test 19495
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
Epoch: 1 cost time: 87.31278443336487
Epoch: 1, Steps: 224 | Train Loss: 0.5285473 Vali Loss: 0.2240302
lr = 0.0009938442
Validation loss decreased (inf --> 0.224030).  Saving model ...
Epoch: 2 cost time: 85.97670435905457
Epoch: 2, Steps: 224 | Train Loss: 0.3760335 Vali Loss: 0.2249536
lr = 0.0009755285
EarlyStopping counter: 1 out of 3
Epoch: 3 cost time: 87.45730686187744
Epoch: 3, Steps: 224 | Train Loss: 0.3311675 Vali Loss: 0.2274167
lr = 0.0009455038
EarlyStopping counter: 2 out of 3
Epoch: 4 cost time: 85.70686411857605
Epoch: 4, Steps: 224 | Train Loss: 0.3038616 Vali Loss: 0.2223306
lr = 0.0009045095
Validation loss decreased (0.224030 --> 0.222331).  Saving model ...
Epoch: 5 cost time: 86.55799317359924
Epoch: 5, Steps: 224 | Train Loss: 0.2875287 Vali Loss: 0.2259898
lr = 0.0008535549
EarlyStopping counter: 1 out of 3
Epoch: 6 cost time: 86.80484318733215
Epoch: 6, Steps: 224 | Train Loss: 0.2754203 Vali Loss: 0.2287793
lr = 0.0007938947
EarlyStopping counter: 2 out of 3
Epoch: 7 cost time: 85.26958727836609
Epoch: 7, Steps: 224 | Train Loss: 0.2653826 Vali Loss: 0.2266256
lr = 0.0007269980
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
test shape: (76, 256, 96, 1) (76, 256, 96, 1)
test shape: (19456, 96, 1) (19456, 96, 1)
mae:0.3743, mse:0.3360, rmse:0.5796, smape:56.2319
self.enc_in = 7
self.data_x = (8640, 7)
train 57463
self.enc_in = 7
self.data_x = (3216, 7)
val 19495
self.enc_in = 7
self.data_x = (3216, 7)
test 19495
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
Epoch: 1 cost time: 85.36107635498047
Epoch: 1, Steps: 224 | Train Loss: 0.5094237 Vali Loss: 0.2143645
lr = 0.0009938442
Validation loss decreased (inf --> 0.214365).  Saving model ...
Epoch: 2 cost time: 85.42863368988037
Epoch: 2, Steps: 224 | Train Loss: 0.3490520 Vali Loss: 0.2215951
lr = 0.0009755285
EarlyStopping counter: 1 out of 3
Epoch: 3 cost time: 84.3506588935852
Epoch: 3, Steps: 224 | Train Loss: 0.3126560 Vali Loss: 0.2123133
lr = 0.0009455038
Validation loss decreased (0.214365 --> 0.212313).  Saving model ...
Epoch: 4 cost time: 86.33714318275452
Epoch: 4, Steps: 224 | Train Loss: 0.2907830 Vali Loss: 0.2118737
lr = 0.0009045095
Validation loss decreased (0.212313 --> 0.211874).  Saving model ...
Epoch: 5 cost time: 86.61622619628906
Epoch: 5, Steps: 224 | Train Loss: 0.2783282 Vali Loss: 0.2157228
lr = 0.0008535549
EarlyStopping counter: 1 out of 3
Epoch: 6 cost time: 84.85854482650757
Epoch: 6, Steps: 224 | Train Loss: 0.2667731 Vali Loss: 0.2154831
lr = 0.0007938947
EarlyStopping counter: 2 out of 3
Epoch: 7 cost time: 85.11560225486755
Epoch: 7, Steps: 224 | Train Loss: 0.2546382 Vali Loss: 0.2134207
lr = 0.0007269980
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
test shape: (76, 256, 96, 1) (76, 256, 96, 1)
test shape: (19456, 96, 1) (19456, 96, 1)
mae:0.3634, mse:0.3106, rmse:0.5573, smape:55.6485
mse_mean = 0.3191, mse_std = 0.0119
mae_mean = 0.3666, mae_std = 0.0055
