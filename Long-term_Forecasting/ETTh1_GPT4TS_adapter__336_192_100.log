self.enc_in = 7
self.data_x = (8640, 7)
train 56791
self.enc_in = 7
self.data_x = (3216, 7)
val 18823
self.enc_in = 7
self.data_x = (3216, 7)
test 18823
gpt2 = GPT2AdapterModel(
  (transformer): GPT2Model(
    (wte): Embedding(50257, 768)
    (wpe): Embedding(1024, 768)
    (drop): Dropout(p=0.1, inplace=False)
    (h): ModuleList(
      (0-5): 6 x GPT2BlockWithAdapters(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): GPT2AttentionWithAdapters(
          (c_attn): MergedLinear(
            in_features=768, out_features=2304, bias=True
            (loras): ModuleDict()
          )
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
          (prefix_tuning): PrefixTuningLayer(
            (prefix_gates): ModuleDict()
            (pool): PrefixTuningPool(
              (prefix_tunings): ModuleDict()
            )
          )
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): GPT2MLP(
          (c_fc): Linear(
            in_features=768, out_features=3072, bias=True
            (loras): ModuleDict()
          )
          (c_proj): Linear(
            in_features=3072, out_features=768, bias=True
            (loras): ModuleDict()
          )
          (act): NewGELUActivation()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (attention_adapters): BottleneckLayer(
          (adapters): ModuleDict(
            (ts_adapter): Adapter(
              (non_linearity): Activation_Function_Class(
                (f): SiLUActivation()
              )
              (adapter_down): Sequential(
                (0): Linear(in_features=768, out_features=48, bias=True)
                (1): Activation_Function_Class(
                  (f): SiLUActivation()
                )
              )
              (adapter_up): Linear(in_features=48, out_features=768, bias=True)
            )
          )
          (adapter_fusion_layer): ModuleDict()
        )
        (output_adapters): BottleneckLayer(
          (adapters): ModuleDict(
            (ts_adapter): Adapter(
              (non_linearity): Activation_Function_Class(
                (f): SiLUActivation()
              )
              (adapter_down): Sequential(
                (0): Linear(in_features=768, out_features=48, bias=True)
                (1): Activation_Function_Class(
                  (f): SiLUActivation()
                )
              )
              (adapter_up): Linear(in_features=48, out_features=768, bias=True)
            )
          )
          (adapter_fusion_layer): ModuleDict()
        )
      )
    )
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (invertible_adapters): ModuleDict()
    (shared_parameters): ModuleDict()
    (prefix_tuning): PrefixTuningPool(
      (prefix_tunings): ModuleDict()
    )
  )
  (heads): ModuleDict(
    (default): CausalLMHead(
      (0): Linear(in_features=768, out_features=50257, bias=False)
    )
  )
)
transformer.wpe.weight
transformer.h.0.ln_1.weight
transformer.h.0.ln_1.bias
transformer.h.0.ln_2.weight
transformer.h.0.ln_2.bias
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.1.ln_1.weight
transformer.h.1.ln_1.bias
transformer.h.1.ln_2.weight
transformer.h.1.ln_2.bias
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.2.ln_1.weight
transformer.h.2.ln_1.bias
transformer.h.2.ln_2.weight
transformer.h.2.ln_2.bias
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.3.ln_1.weight
transformer.h.3.ln_1.bias
transformer.h.3.ln_2.weight
transformer.h.3.ln_2.bias
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.4.ln_1.weight
transformer.h.4.ln_1.bias
transformer.h.4.ln_2.weight
transformer.h.4.ln_2.bias
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.5.ln_1.weight
transformer.h.5.ln_1.bias
transformer.h.5.ln_2.weight
transformer.h.5.ln_2.bias
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.ln_f.weight
transformer.ln_f.bias
Epoch: 1 cost time: 79.3348560333252
Epoch: 1, Steps: 221 | Train Loss: 0.4784898 Vali Loss: 0.9815312
lr = 0.0009938442
Validation loss decreased (inf --> 0.981531).  Saving model ...
Epoch: 2 cost time: 79.36339354515076
Epoch: 2, Steps: 221 | Train Loss: 0.3744007 Vali Loss: 1.0148481
lr = 0.0009755285
EarlyStopping counter: 1 out of 3
Epoch: 3 cost time: 79.32875204086304
Epoch: 3, Steps: 221 | Train Loss: 0.3364064 Vali Loss: 1.0846349
lr = 0.0009455038
EarlyStopping counter: 2 out of 3
Epoch: 4 cost time: 79.60811614990234
Epoch: 4, Steps: 221 | Train Loss: 0.2969161 Vali Loss: 1.1061250
lr = 0.0009045095
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
test shape: (73, 256, 192, 1) (73, 256, 192, 1)
test shape: (18688, 192, 1) (18688, 192, 1)
mae:0.4331, mse:0.4297, rmse:0.6555, smape:77.7480
self.enc_in = 7
self.data_x = (8640, 7)
train 56791
self.enc_in = 7
self.data_x = (3216, 7)
val 18823
self.enc_in = 7
self.data_x = (3216, 7)
test 18823
gpt2 = GPT2AdapterModel(
  (transformer): GPT2Model(
    (wte): Embedding(50257, 768)
    (wpe): Embedding(1024, 768)
    (drop): Dropout(p=0.1, inplace=False)
    (h): ModuleList(
      (0-5): 6 x GPT2BlockWithAdapters(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): GPT2AttentionWithAdapters(
          (c_attn): MergedLinear(
            in_features=768, out_features=2304, bias=True
            (loras): ModuleDict()
          )
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
          (prefix_tuning): PrefixTuningLayer(
            (prefix_gates): ModuleDict()
            (pool): PrefixTuningPool(
              (prefix_tunings): ModuleDict()
            )
          )
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): GPT2MLP(
          (c_fc): Linear(
            in_features=768, out_features=3072, bias=True
            (loras): ModuleDict()
          )
          (c_proj): Linear(
            in_features=3072, out_features=768, bias=True
            (loras): ModuleDict()
          )
          (act): NewGELUActivation()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (attention_adapters): BottleneckLayer(
          (adapters): ModuleDict(
            (ts_adapter): Adapter(
              (non_linearity): Activation_Function_Class(
                (f): SiLUActivation()
              )
              (adapter_down): Sequential(
                (0): Linear(in_features=768, out_features=48, bias=True)
                (1): Activation_Function_Class(
                  (f): SiLUActivation()
                )
              )
              (adapter_up): Linear(in_features=48, out_features=768, bias=True)
            )
          )
          (adapter_fusion_layer): ModuleDict()
        )
        (output_adapters): BottleneckLayer(
          (adapters): ModuleDict(
            (ts_adapter): Adapter(
              (non_linearity): Activation_Function_Class(
                (f): SiLUActivation()
              )
              (adapter_down): Sequential(
                (0): Linear(in_features=768, out_features=48, bias=True)
                (1): Activation_Function_Class(
                  (f): SiLUActivation()
                )
              )
              (adapter_up): Linear(in_features=48, out_features=768, bias=True)
            )
          )
          (adapter_fusion_layer): ModuleDict()
        )
      )
    )
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (invertible_adapters): ModuleDict()
    (shared_parameters): ModuleDict()
    (prefix_tuning): PrefixTuningPool(
      (prefix_tunings): ModuleDict()
    )
  )
  (heads): ModuleDict(
    (default): CausalLMHead(
      (0): Linear(in_features=768, out_features=50257, bias=False)
    )
  )
)
transformer.wpe.weight
transformer.h.0.ln_1.weight
transformer.h.0.ln_1.bias
transformer.h.0.ln_2.weight
transformer.h.0.ln_2.bias
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.1.ln_1.weight
transformer.h.1.ln_1.bias
transformer.h.1.ln_2.weight
transformer.h.1.ln_2.bias
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.2.ln_1.weight
transformer.h.2.ln_1.bias
transformer.h.2.ln_2.weight
transformer.h.2.ln_2.bias
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.3.ln_1.weight
transformer.h.3.ln_1.bias
transformer.h.3.ln_2.weight
transformer.h.3.ln_2.bias
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.4.ln_1.weight
transformer.h.4.ln_1.bias
transformer.h.4.ln_2.weight
transformer.h.4.ln_2.bias
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.5.ln_1.weight
transformer.h.5.ln_1.bias
transformer.h.5.ln_2.weight
transformer.h.5.ln_2.bias
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.ln_f.weight
transformer.ln_f.bias
Epoch: 1 cost time: 79.17826890945435
Epoch: 1, Steps: 221 | Train Loss: 0.4956312 Vali Loss: 0.9471065
lr = 0.0009938442
Validation loss decreased (inf --> 0.947107).  Saving model ...
Epoch: 2 cost time: 79.60181856155396
Epoch: 2, Steps: 221 | Train Loss: 0.3826046 Vali Loss: 0.9883055
lr = 0.0009755285
EarlyStopping counter: 1 out of 3
Epoch: 3 cost time: 79.51577973365784
Epoch: 3, Steps: 221 | Train Loss: 0.3499477 Vali Loss: 1.0385630
lr = 0.0009455038
EarlyStopping counter: 2 out of 3
Epoch: 4 cost time: 79.85372471809387
Epoch: 4, Steps: 221 | Train Loss: 0.3139896 Vali Loss: 1.0604595
lr = 0.0009045095
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
test shape: (73, 256, 192, 1) (73, 256, 192, 1)
test shape: (18688, 192, 1) (18688, 192, 1)
mae:0.4281, mse:0.4282, rmse:0.6544, smape:77.5614
self.enc_in = 7
self.data_x = (8640, 7)
train 56791
self.enc_in = 7
self.data_x = (3216, 7)
val 18823
self.enc_in = 7
self.data_x = (3216, 7)
test 18823
gpt2 = GPT2AdapterModel(
  (transformer): GPT2Model(
    (wte): Embedding(50257, 768)
    (wpe): Embedding(1024, 768)
    (drop): Dropout(p=0.1, inplace=False)
    (h): ModuleList(
      (0-5): 6 x GPT2BlockWithAdapters(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): GPT2AttentionWithAdapters(
          (c_attn): MergedLinear(
            in_features=768, out_features=2304, bias=True
            (loras): ModuleDict()
          )
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
          (prefix_tuning): PrefixTuningLayer(
            (prefix_gates): ModuleDict()
            (pool): PrefixTuningPool(
              (prefix_tunings): ModuleDict()
            )
          )
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): GPT2MLP(
          (c_fc): Linear(
            in_features=768, out_features=3072, bias=True
            (loras): ModuleDict()
          )
          (c_proj): Linear(
            in_features=3072, out_features=768, bias=True
            (loras): ModuleDict()
          )
          (act): NewGELUActivation()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (attention_adapters): BottleneckLayer(
          (adapters): ModuleDict(
            (ts_adapter): Adapter(
              (non_linearity): Activation_Function_Class(
                (f): SiLUActivation()
              )
              (adapter_down): Sequential(
                (0): Linear(in_features=768, out_features=48, bias=True)
                (1): Activation_Function_Class(
                  (f): SiLUActivation()
                )
              )
              (adapter_up): Linear(in_features=48, out_features=768, bias=True)
            )
          )
          (adapter_fusion_layer): ModuleDict()
        )
        (output_adapters): BottleneckLayer(
          (adapters): ModuleDict(
            (ts_adapter): Adapter(
              (non_linearity): Activation_Function_Class(
                (f): SiLUActivation()
              )
              (adapter_down): Sequential(
                (0): Linear(in_features=768, out_features=48, bias=True)
                (1): Activation_Function_Class(
                  (f): SiLUActivation()
                )
              )
              (adapter_up): Linear(in_features=48, out_features=768, bias=True)
            )
          )
          (adapter_fusion_layer): ModuleDict()
        )
      )
    )
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (invertible_adapters): ModuleDict()
    (shared_parameters): ModuleDict()
    (prefix_tuning): PrefixTuningPool(
      (prefix_tunings): ModuleDict()
    )
  )
  (heads): ModuleDict(
    (default): CausalLMHead(
      (0): Linear(in_features=768, out_features=50257, bias=False)
    )
  )
)
transformer.wpe.weight
transformer.h.0.ln_1.weight
transformer.h.0.ln_1.bias
transformer.h.0.ln_2.weight
transformer.h.0.ln_2.bias
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.0.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.0.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.1.ln_1.weight
transformer.h.1.ln_1.bias
transformer.h.1.ln_2.weight
transformer.h.1.ln_2.bias
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.1.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.1.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.2.ln_1.weight
transformer.h.2.ln_1.bias
transformer.h.2.ln_2.weight
transformer.h.2.ln_2.bias
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.2.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.2.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.3.ln_1.weight
transformer.h.3.ln_1.bias
transformer.h.3.ln_2.weight
transformer.h.3.ln_2.bias
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.3.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.3.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.4.ln_1.weight
transformer.h.4.ln_1.bias
transformer.h.4.ln_2.weight
transformer.h.4.ln_2.bias
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.4.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.4.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.5.ln_1.weight
transformer.h.5.ln_1.bias
transformer.h.5.ln_2.weight
transformer.h.5.ln_2.bias
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.5.attention_adapters.adapters.ts_adapter.adapter_up.bias
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_down.0.weight
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_down.0.bias
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_up.weight
transformer.h.5.output_adapters.adapters.ts_adapter.adapter_up.bias
transformer.ln_f.weight
transformer.ln_f.bias
Epoch: 1 cost time: 79.33688950538635
Epoch: 1, Steps: 221 | Train Loss: 0.4761678 Vali Loss: 0.9694905
lr = 0.0009938442
Validation loss decreased (inf --> 0.969490).  Saving model ...
Epoch: 2 cost time: 79.56468868255615
Epoch: 2, Steps: 221 | Train Loss: 0.3676511 Vali Loss: 1.0222946
lr = 0.0009755285
EarlyStopping counter: 1 out of 3
Epoch: 3 cost time: 79.60222482681274
Epoch: 3, Steps: 221 | Train Loss: 0.3234954 Vali Loss: 1.1314534
lr = 0.0009455038
EarlyStopping counter: 2 out of 3
Epoch: 4 cost time: 79.58741641044617
Epoch: 4, Steps: 221 | Train Loss: 0.2830271 Vali Loss: 1.1205436
lr = 0.0009045095
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
test shape: (73, 256, 192, 1) (73, 256, 192, 1)
test shape: (18688, 192, 1) (18688, 192, 1)
mae:0.4354, mse:0.4386, rmse:0.6623, smape:75.7752
mse_mean = 0.4322, mse_std = 0.0046
mae_mean = 0.4322, mae_std = 0.0031
